{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Testing\n",
    "\n",
    "Testing is an easy thing to understand but there is also an art to it as well; writing good tests often requires you to try to figure out *what input(s) are most likely to break your program*. \n",
    "\n",
    "In addition to this, tests can serve different purposes as well:\n",
    "\n",
    "* Testing for correctness\n",
    "* Testing for speed (benchmarking)\n",
    "* Testing for \"Let's check I didn't fuck something up\"  (a.k.a 'regression testing')\n",
    "* ...etc...\n",
    "\n",
    "All of the above tests have their uses, but as a general rule of thumb a good test suite will include a range of inputs and multiple tests for each. \n",
    "\n",
    "I would add a small caveat that if there is documentation for a function that says something like \"does not work for strings\" then although it is possible to write test code for strings what would be the point? The documentation makes it clear that these tests will fail. Instead of writing test code for situations the code was **not designed to solve** focus on 'realistic' test cases.\n",
    "\n",
    "Alright, lets write a super simple function that divides A by B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    \"\"\"\"a, b are ints or floats. Returns a/b\"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so, this is where we need to put our ‘thinking hat’ on for a moment. The documentation for this function specifically states A and B are supposed to be numbers, so instead of wasting time breaking the code with obviously bad inputs (e.g strings) lets try to break with valid inputs. In other words: \n",
    "\n",
    "> what are the possible integers/floats we can pass in where this function may break?\n",
    "\n",
    "When dealing with numbers there are, I think, three basic tests that are almost always worth running:\n",
    "\n",
    "1. Negative Numbers\n",
    "1. Zero\n",
    "1. Positive Numbers\n",
    "\n",
    "And in addition to those tests we should also run tests for:\n",
    "\n",
    "1. Small inputs (e.g 10/5)\n",
    "1. Very large inputs (e.g 999342493249234234234234 / 234234244353452424 )\n",
    "\n",
    "You may remember for example in lecture 21 as we tried to optimise our is_prime function we introduced some defects when working with small numbers.\n",
    "\n",
    "Anyway, the point is these five basic cases will cover a lot of situations you may have with numbers. Obviously you should run several tests for each of these basic test cases. **And in addition to the basic tests you should run more function specific tests too**; for example, if I have a function that returns the factors of n then it would be wise to run a bunch of tests with prime numbers to check what happens there. You should also test [*highly composite numbers*](https://en.wikipedia.org/wiki/Highly_composite_number) too (e.g 720, 1260). In regard to our division function a good additional test would be when the numerator is larger than the denominator and vice versa (e.g. try both 10/2 and 2/10). Zero is also a special case for division, but we have already listed it in the basic tests.  \n",
    "\n",
    "Okay, so lets write our first tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function here...\n",
    "print (divide(10, 2) == 5.0)\n",
    "[divide(10.0, 2.0) == 5.0, divide(10,2) == 5.0, divide(0, 1) == 0.0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we know that X/0 is a ZeroDivisionError, the question is what do we want the result to be? Do we want Python to raise the error? or would we prefer Python to do something else such as return a number or perhaps a string.\n",
    "\n",
    "Remember that errors are not bad, if Python to throws an error when it gets zero as input that’s totally fine, and in this case I think I’m happy with the error. This means I have to write a test case that **expects** an error to be raised. We can do that like so…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    divide(1, 0)\n",
    "    print(False) # note that if the above line of code yields a zeroDiv error, this line of code is not executed. \n",
    "except ZeroDivisionError:\n",
    "    print(True) # Test pass, dividing by zero yields an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, next up we need to test for large numbers. When it came to small numbers we can easily work out the correct answer by hand, but for large sums that’s not so easy. \n",
    " \n",
    "Your first instinct here might be to say \"use a calculator\" and while that’s true, that solution only works in this very specific case. What we actually want is a more general solution that can solve all sorts of problems. \n",
    " \n",
    "It turns out that sometimes building code that can generate test cases is a lot easier that building the solver. In this particular example we can do just that...\n",
    " \n",
    "Let's take a step back and ask ourselves what division actually is. The answer is basically the opposite of multiplication. And so, we can actually write test cases for our function by \"reverse engineering\" the problem. We know from math that the following is always true: \n",
    " \n",
    "    (y * y) / y = y\n",
    "    (x * y) / y = x\n",
    " \n",
    "And so, so long as we have a function that multiplies correctly, we can be confident that our function is getting the right answer to complex division problems *even though* we do not know what the right answer is ourselves. In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 30202020202020202022424354265674567456\n",
    "y = 95334534534543543543545435543543545345\n",
    "\n",
    "divide(y * y, y) == float(y)\n",
    "divide(x * y, y) == float(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time however, the code you want to test will not be so easily reversed engineered. So most of the time your tests are going to be hand-written. And because writing tests can be a bit tedious and time consuming you are going to want tests that are:\n",
    "\n",
    "* Fast to write and execute\n",
    "* Easy to understand, they should give clear feedback on what went wrong\n",
    "* Test most/all of the likely scenarios.\n",
    "\n",
    "For these reasons, its often a good idea to write tests that follow a common format. Great tests are often tests that you can copy and paste, and change into a new test by changing a small handful of values. \n",
    "\n",
    "To illustrate that, lets suppose I have the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMissingPositive(nums):\n",
    "    \"\"\"\n",
    "    Given an unsorted integer array (nums) finds the smallest missing positive integer.\n",
    "    \n",
    "    for example: \n",
    "    [0,1,2,3]  => returns 4, since 4 is the smallest missing number\n",
    "    [10,11,12] => returns 1\n",
    "    \"\"\"\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually a [hard problem](https://leetcode.com/problems/first-missing-positive/) to solve efficiently but I don't care about that. Right now, I only care about testing. And this is function that is easy to test.\n",
    "\n",
    "## Test-Driven Development\n",
    "\n",
    "Sometimes, software developers write tests before they actually write the solution to thier problem. This is called \"test-driven development\". The advantage of writing tests first is that it forces you to think about the problem in a different way. Instead of thinking about how to solve the problem we instead start out by thinking about the sorts of inputs that are difficult. Sometimes, that means we spot problems faster than we would have otherwise.\n",
    "\n",
    "Okay, lets write some tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(firstMissingPositive([1,2,3]) == 4)\n",
    "print(firstMissingPositive([0,0,1]) == 2)\n",
    "print(firstMissingPositive([1,2]) == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have some tests, if \"False\" gets printed that means the test failed. This is a good start. Notice how these tests are easy to write and understand. We can also quickly add tests by copy & paste plus some tweaks. On the downside, the output is not very informative; Why did a test fail? Here our only option is figure out what test failed and then re-run it, this time makeing a not of the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 3\n",
      "should be 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Got:\", firstMissingPositive([1,2,3]))\n",
    "print(\"should be 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so if we want better test output, we should probably write some sort of 'test framework'. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FAILED (Got: 3 Expected: 4, Input was: [1, 2, 3])\n",
      "TEST FAILED (Got: 3 Expected: 2, Input was: [0, 0, 1])\n",
      "TEST PASSED\n",
      "TEST FAILED (Got: 3 Expected: 1, Input was: [7, 6, 5, 4, 3, 2])\n",
      "TEST PASSED\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "def print_test_result(func, input_val, expected_val):\n",
    "    \n",
    "    result = func(input_val)\n",
    "    if result == expected_val:\n",
    "        print(f\"TEST PASSED\")\n",
    "    else:\n",
    "        print(f\"TEST FAILED (Got: {result} Expected: {expected_val}, Input was: {input_val})\")\n",
    "\n",
    "    \n",
    "    \n",
    "##### TESTS GO HERE #####\n",
    "print_test_result(firstMissingPositive, [1,2,3], 4)\n",
    "print_test_result(firstMissingPositive, [0,0,1], 2)\n",
    "print_test_result(firstMissingPositive, [1,2], 3)\n",
    "print_test_result(firstMissingPositive, [7,6,5,4,3,2], 1)\n",
    "print_test_result(firstMissingPositive, [1,2,4], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so know that we have spent a little bit of time working on a test framework we can (a) quickly write new tests and (b) we can also clearly see why a test failed. \n",
    "\n",
    "In test-driven development once you have a small selection of tests you then try to write code that passes the tests. Let's do that now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMissingPositive(nums):\n",
    "    \"\"\"\n",
    "    Given an unsorted integer array (nums) finds the smallest missing positive integer.\n",
    "    \n",
    "    for example: \n",
    "    [0,1,2,3]  => returns 4, since 4 is the smallest missing number\n",
    "    [10,11,12] => returns 1\n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i not in nums:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have a solution, lets run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST PASSED\n",
      "TEST PASSED\n",
      "TEST PASSED\n",
      "TEST FAILED (Got: 8 Expected: 1, Input was: [7, 6, 5, 4, 3, 2])\n",
      "TEST PASSED\n"
     ]
    }
   ],
   "source": [
    "print_test_result(firstMissingPositive, [1,2,3], 4)\n",
    "print_test_result(firstMissingPositive, [0,0,1], 2)\n",
    "print_test_result(firstMissingPositive, [1,2], 3)\n",
    "print_test_result(firstMissingPositive, [7,6,5,4,3,2], 1)\n",
    "print_test_result(firstMissingPositive, [1,2,4], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One test has failed, can you spot what the problem is? \n",
    "\n",
    "When you have a failing test, and you are not sure exactly what the problem is a good thing to do is to try to make the test as simple as possible. Let's try that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FAILED (Got: 6 Expected: 1, Input was: [5, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print_test_result(firstMissingPositive, [5,4,3,2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we have simplified the test and it still fails. Lets make it even simpler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FAILED (Got: 3 Expected: 1, Input was: [2])\n",
      "TEST FAILED (Got: 2 Expected: 1, Input was: [])\n"
     ]
    }
   ],
   "source": [
    "print_test_result(firstMissingPositive, [2], 1)\n",
    "print_test_result(firstMissingPositive, [], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now its not really possible to make the test any simpler. But by now the problem should be easy to understand; it seems as if the first number we are looking for is 2, so if 1 is missing we fail.\n",
    "\n",
    "Lets test that hypothesis by writing more tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST PASSED\n",
      "TEST PASSED\n",
      "TEST PASSED\n"
     ]
    }
   ],
   "source": [
    "print_test_result(firstMissingPositive, [1,2,3], 4)\n",
    "print_test_result(firstMissingPositive, [1, 3], 2)\n",
    "print_test_result(firstMissingPositive, [1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can try to fix the function for homework.\n",
    "\n",
    "\n",
    "Anyway, we built our own test framework for this example. It turns out that we do not need to do that, Python has a lot of frameworks that have been built by other developers far smarter than myself. And so, instead of re-inventing the wheel we should probably just learn on of these frameworks.\n",
    "There are several options, but in this lecture I shall cover 'doc testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doctesting\n",
    "\n",
    "You may remember docstrings, the text we put at the very start of a function. Well, write doctests all we have to do is add tests to our docstrings. Its honestly as simple as that. Here is the syntax for a doctest:\n",
    "    \n",
    "    \"\"\" \n",
    "    >>> {function name} ( {function argument, if any} )\n",
    "    {expected result}\n",
    "    \"\"\"\n",
    "\n",
    "And then once you have done that, you'll need to copy & paste the code below to run the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_doctests():\n",
    "    import doctest\n",
    "    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default if all your tests pass nothing will be printed, but should a doctest fail Python will give you all the juicy detail. Lets try it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    \"\"\"    \n",
    "    >>> add(10, 10)\n",
    "    20\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "run_doctests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran doctests, but since the test past nothing happened. Alright, lets show you want happens on failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 9, in __main__.run_all_the_tests\n",
      "Failed example:\n",
      "    20 + 2\n",
      "Expected:\n",
      "    23  \n",
      "Got:\n",
      "    22\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   3 in __main__.run_all_the_tests\n",
      "***Test Failed*** 1 failures.\n"
     ]
    }
   ],
   "source": [
    "def run_all_the_tests():   \n",
    "    \"\"\"    \n",
    "    >>> 1 + 1\n",
    "    2\n",
    "    \n",
    "    >>> print(True)\n",
    "    True\n",
    "    \n",
    "    >>> 20 + 2\n",
    "    23  \n",
    "    \"\"\"   \n",
    "\n",
    "    print(\"testing complete\")\n",
    "    \n",
    "run_doctests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Python ran four tests and two of them failed. It turns out 20 + 2 does not equal 23 and bad_list (surprise surprise) it up to no good. \n",
    "\n",
    "Overall, I'd recommend beginners use doctesting. Its fairly easy to use and it allows you to quickly type out basic tests for your functions.\n",
    "\n",
    "As our final exerise for today lets convert our 'print_test_result' tests into doctests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    firstMissingPositive([1,2,3])\n",
      "Expecting:\n",
      "    4\n",
      "ok\n",
      "Trying:\n",
      "    firstMissingPositive([0,0,1])\n",
      "Expecting:\n",
      "    2\n",
      "ok\n",
      "Trying:\n",
      "    firstMissingPositive([1,2])\n",
      "Expecting:\n",
      "    3\n",
      "ok\n",
      "Trying:\n",
      "    firstMissingPositive([1,2,4])\n",
      "Expecting:\n",
      "    3\n",
      "ok\n",
      "Trying:\n",
      "    firstMissingPositive([2])\n",
      "Expecting:\n",
      "    1\n",
      "**********************************************************************\n",
      "File \"__main__\", line 11, in NoName\n",
      "Failed example:\n",
      "    firstMissingPositive([2])\n",
      "Expected:\n",
      "    1\n",
      "Got:\n",
      "    3\n"
     ]
    }
   ],
   "source": [
    "def firstMissingPositive_TESTS():\n",
    "    \"\"\"\n",
    "    >>> firstMissingPositive([1,2,3])\n",
    "    4\n",
    "    >>> firstMissingPositive([0,0,1])\n",
    "    2\n",
    "    >>> firstMissingPositive([1,2])\n",
    "    3\n",
    "    >>> firstMissingPositive([1,2,4])\n",
    "    3\n",
    "    >>> firstMissingPositive([2])\n",
    "    1\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Now we run the tests...\n",
    "import doctest\n",
    "doctest.run_docstring_examples(firstMissingPositive_TESTS, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
